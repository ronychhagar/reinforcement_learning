{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install 'shimmy>=0.2.1'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsJkbOes4yuk",
        "outputId": "2357409f-fd49-4885-e68a-1c5170f68050"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shimmy>=0.2.1 in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy>=0.2.1) (1.23.5)\n",
            "Requirement already satisfied: gymnasium>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from shimmy>=0.2.1) (0.29.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (4.7.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy>=0.2.1) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wReN8DHXtL-l",
        "outputId": "d175b9aa-e78a-4177-e5f1-5afc9f37288a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 106      |\n",
            "|    ep_rew_mean     | -332     |\n",
            "| time/              |          |\n",
            "|    fps             | 668      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 177         |\n",
            "|    ep_rew_mean          | -995        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 500         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 8           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016696088 |\n",
            "|    clip_fraction        | 0.0789      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.39       |\n",
            "|    explained_variance   | 0.000325    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.05e+04    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0084     |\n",
            "|    value_loss           | 2.12e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 61.8        |\n",
            "|    ep_rew_mean          | -276        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 11          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017774917 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.34       |\n",
            "|    explained_variance   | 0.000176    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 599         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0228     |\n",
            "|    value_loss           | 2.06e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 20.2        |\n",
            "|    ep_rew_mean          | -39.2       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 571         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013763328 |\n",
            "|    clip_fraction        | 0.302       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.28       |\n",
            "|    explained_variance   | 6.31e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 152         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0274     |\n",
            "|    value_loss           | 325         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 15.3        |\n",
            "|    ep_rew_mean          | -26.3       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 576         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 17          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018386489 |\n",
            "|    clip_fraction        | 0.364       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.2        |\n",
            "|    explained_variance   | 5.86e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 143         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0385     |\n",
            "|    value_loss           | 248         |\n",
            "-----------------------------------------\n",
            "Current Temperature: 24.7\n",
            "Current Temperature: 24.3\n",
            "Current Temperature: 23.900000000000002\n",
            "Current Temperature: 23.500000000000004\n",
            "Current Temperature: 23.300000000000004\n",
            "Current Temperature: 23.000000000000004\n",
            "Current Temperature: 22.800000000000004\n",
            "Current Temperature: 22.400000000000006\n",
            "Target temperature reached!\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "import time\n",
        "\n",
        "class ThermalManagementEnv(gym.Env):\n",
        "    def __init__(self, target_temp):\n",
        "        super(ThermalManagementEnv, self).__init__()\n",
        "        self.target_temp = target_temp\n",
        "        self.current_temp = 25.0  # Initial temperature\n",
        "        self.max_fan_speed = 10   # Maximum fan speed\n",
        "        self.min_fan_speed = 0    # Minimum fan speed\n",
        "        self.action_space = gym.spaces.Discrete(self.max_fan_speed + 1)\n",
        "        self.observation_space = gym.spaces.Box(low=0, high=100, shape=(1,), dtype=float)\n",
        "\n",
        "    def step(self, action):\n",
        "        fan_speed = action\n",
        "        self.current_temp += (fan_speed / 10) - 0.5  # Simplified temperature dynamics\n",
        "        reward = -abs(self.current_temp - self.target_temp)\n",
        "        done = abs(self.current_temp - self.target_temp) < 0.5\n",
        "        return self.current_temp, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_temp = 25.0\n",
        "        return self.current_temp\n",
        "\n",
        "target_temp = 22.0\n",
        "env = ThermalManagementEnv(target_temp)\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=10000)\n",
        "model.save(\"thermal_management_model\")\n",
        "\n",
        "loaded_model = PPO.load(\"thermal_management_model\")\n",
        "\n",
        "obs = env.reset()\n",
        "while True:\n",
        "    action, _ = loaded_model.predict([obs])  # No need to reshape the observation\n",
        "    obs, _, done, _ = env.step(action)\n",
        "    print(\"Current Temperature:\", obs)\n",
        "    if done:\n",
        "        print(\"Target temperature reached!\")\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "\n"
      ]
    }
  ]
}